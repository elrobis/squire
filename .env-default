# Whisper
WHISPER_MODEL=large-v3
# Use int8 weights with fp16 activations -> huge VRAM savings, still accurate
WHISPER_COMPUTE=int8_float16
WHISPER_DEVICE=cuda
WHISPER_BEAM_SIZE=5
WHISPER_VAD=true
WHISPER_WORD_TIMESTAMPS=true
WHISPER_LANGUAGE=en  # Force English (speeds up & reduces mistakes)

# Optional perf knobs (envs your app can read & pass through)
CT2_NUM_THREADS=6  # you already export CTRANSLATE2_NUM_THREADS=6; mirror here for app
CT2_USE_CUDNN=1    # 1 to use cuDNN (fast). Set 0 only as a workaround.

# Pyannote (speaker diarization)
HF_TOKEN=HUGGING_FACE_API_KEY_READ_ONLY

PYANNOTE_PIPELINE=pyannote/speaker-diarization-3.1

# Sensible defaults; you can tune later
DIARIZATION_MIN_SPEAKER_DUR=0.8
DIARIZATION_OVERLAP=false

# Ollama
OLLAMA_MODEL=gpt-oss:20b
OLLAMA_HOST=http://127.0.0.1:11434
OLLAMA_NUM_CTX=8192
OLLAMA_KEEP_ALIVE=15m

# Chunking
CHUNK_SEC=480              # 8-minute chunks for summaries
CHUNK_OVERLAP_SEC=30     # small overlap to avoid cutting sentences
EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2
VECTOR_DB=chroma

