from pathlib import Path
import orjson, torch, os, whisper

def transcribe_file(audio_path: Path) -> Path:
    audio_path = Path(audio_path)
    out_dir = Path("data/transcripts"); out_dir.mkdir(parents=True, exist_ok=True)

    device = "cuda" if torch.cuda.is_available() else "cpu"
    name = os.environ.get("WHISPER_MODEL", "medium")  # "small" / "medium" / "large-v3"
    model = whisper.load_model(name, device=device)

    result = model.transcribe(str(audio_path), verbose=False)  # segment-level timestamps

    segs = []
    for s in result["segments"]:
        segs.append({"start": s["start"], "end": s["end"], "text": s["text"], "words": []})

    session_id = audio_path.stem
    json_path = out_dir / f"{session_id}.json"
    txt_path  = out_dir / f"{session_id}.txt"
    json_path.write_bytes(orjson.dumps({"session": session_id, "segments": segs}, option=orjson.OPT_INDENT_2))
    txt_path.write_text("\n".join([s["text"] for s in segs]), encoding="utf-8")
    return json_path